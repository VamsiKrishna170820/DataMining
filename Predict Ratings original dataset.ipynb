{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8ed66c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\mspur\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\mspur\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from scipy.sparse import hstack\n",
    "import warnings\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "\n",
    "df = pd.read_csv('37000_reviews_of_thread_app.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "096e6ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to handle negations\n",
    "def handle_negations(text):\n",
    "    negations = {\"not\", \"no\", \"never\", \"n't\", \"cannot\", \"neither\", \"nor\"}\n",
    "    words = text.split()\n",
    "    negated_text = []\n",
    "    negate = False\n",
    "    for word in words:\n",
    "        if negate and word.isalpha():\n",
    "            negated_text.append(f\"not_{word}\")\n",
    "        else:\n",
    "            negated_text.append(word)\n",
    "        if word in negations or word.endswith(\"n't\"):\n",
    "            negate = True\n",
    "        if word.endswith(('.', '!', '?')):\n",
    "            negate = False\n",
    "    return ' '.join(negated_text)\n",
    "\n",
    "# Enhanced Preprocessing Function\n",
    "def preprocess_text(text):\n",
    "    # Convert text to lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # Handle negations\n",
    "    text = handle_negations(text)\n",
    "\n",
    "    # Remove punctuation and numbers\n",
    "    text = ''.join([char for char in text if char.isalpha() or char.isspace()])\n",
    "\n",
    "    # Tokenization and Lemmatization (not using Spacy)\n",
    "    words = text.split()\n",
    "    lemmatized = [word for word in words]\n",
    "\n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    without_stopwords = [word for word in lemmatized if word not in stop_words]\n",
    "\n",
    "    # Rejoin words\n",
    "    return ' '.join(without_stopwords)\n",
    "\n",
    "# Apply the preprocessing to each review\n",
    "df['preprocessed_reviews'] = df['review_description'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed901fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(max_features=1000)\n",
    "\n",
    "# Fit and transform the preprocessed text data into TF-IDF vectors\n",
    "X = tfidf_vectorizer.fit_transform(df['preprocessed_reviews'])\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# One-hot encode the 'source' column\n",
    "onehot_encoder = OneHotEncoder()\n",
    "source_encoded = onehot_encoder.fit_transform(df[['source']])\n",
    "\n",
    "# Create a TF-IDF vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=1000)\n",
    "\n",
    "# Fit and transform the preprocessed text data into TF-IDF vectors\n",
    "X_text = tfidf_vectorizer.fit_transform(df['preprocessed_reviews'])\n",
    "\n",
    "# Combine the TF-IDF vectors with the one-hot encoded 'source' column\n",
    "X = hstack((X_text, source_encoded))\n",
    "\n",
    "# Assuming your target variable is in df['rating']\n",
    "y = df['rating']\n",
    "\n",
    "# Map numerical ratings to textual labels if that's not already done\n",
    "df['rating_label'] = df['rating'].map({1: 'Low', 2: 'Low', 3: 'Medium', 4: 'High', 5: 'High'})\n",
    "\n",
    "# Update y to use these new textual labels\n",
    "y = df['rating_label']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dfd72619",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e691cbd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Metrics:\n",
      "Accuracy: 0.7266985473247316\n",
      "Decision Tree Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        High       0.77      0.86      0.81      6104\n",
      "         Low       0.73      0.66      0.70      4073\n",
      "      Medium       0.20      0.12      0.15       906\n",
      "\n",
      "    accuracy                           0.73     11083\n",
      "   macro avg       0.57      0.55      0.55     11083\n",
      "weighted avg       0.71      0.73      0.71     11083\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize and fit the Decision Tree Classifier model\n",
    "dt_model = DecisionTreeClassifier(random_state=42)\n",
    "dt_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_dt = dt_model.predict(X_test)\n",
    "\n",
    "accuracy_dt = accuracy_score(y_test, y_pred_dt)\n",
    "\n",
    "print(\"Decision Tree Metrics:\")\n",
    "print(\"Accuracy:\", accuracy_dt)\n",
    "\n",
    "class_report_dt = classification_report(y_test, y_pred_dt)\n",
    "print(\"Decision Tree Classification Report:\\n\", class_report_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc6f2235",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7756925020301363\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        High       0.80      0.90      0.84      6104\n",
      "         Low       0.75      0.76      0.76      4073\n",
      "      Medium       0.30      0.02      0.04       906\n",
      "\n",
      "    accuracy                           0.78     11083\n",
      "   macro avg       0.61      0.56      0.54     11083\n",
      "weighted avg       0.74      0.78      0.75     11083\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize and fit the Random Forest Classifier model\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_rf)\n",
    "class_report = classification_report(y_test, y_pred_rf)\n",
    "print(\"Classification Report:\\n\", class_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "065d46bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Multinomial Naive Bayes Metrics:\n",
      "Accuracy: 0.7757827303076784\n",
      "Multinomial Naive Bayes Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        High       0.79      0.91      0.84      6104\n",
      "         Low       0.78      0.73      0.75      4073\n",
      "      Medium       0.36      0.08      0.13       906\n",
      "\n",
      "    accuracy                           0.78     11083\n",
      "   macro avg       0.64      0.57      0.58     11083\n",
      "weighted avg       0.75      0.78      0.75     11083\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize and fit the Multinomial Naive Bayes (MultinomialNB) model\n",
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred_nb = nb_model.predict(X_test)\n",
    "\n",
    "\n",
    "accuracy_nb = accuracy_score(y_test, y_pred_nb)\n",
    "\n",
    "print(\"\\nMultinomial Naive Bayes Metrics:\")\n",
    "print(\"Accuracy:\", accuracy_nb)\n",
    "\n",
    "\n",
    "class_report_nb = classification_report(y_test, y_pred_nb)\n",
    "print(\"Multinomial Naive Bayes Classification Report:\\n\", class_report_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "33e40cfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Linear Support Vector Classifier (LinearSVC) Metrics:\n",
      "Accuracy: 0.7798430027970766\n",
      "Linear Support Vector Classifier (LinearSVC) Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        High       0.78      0.92      0.85      6104\n",
      "         Low       0.79      0.73      0.76      4073\n",
      "      Medium       0.34      0.05      0.08       906\n",
      "\n",
      "    accuracy                           0.78     11083\n",
      "   macro avg       0.64      0.57      0.56     11083\n",
      "weighted avg       0.75      0.78      0.75     11083\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize and fit the Linear Support Vector Classifier (LinearSVC) model\n",
    "svc_model = LinearSVC(random_state=42)\n",
    "svc_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_svc = svc_model.predict(X_test)\n",
    "\n",
    "\n",
    "accuracy_svc = accuracy_score(y_test, y_pred_svc)\n",
    "print(\"\\nLinear Support Vector Classifier (LinearSVC) Metrics:\")\n",
    "print(\"Accuracy:\", accuracy_svc)\n",
    "\n",
    "class_report_svc = classification_report(y_test, y_pred_svc)\n",
    "print(\"Linear Support Vector Classifier (LinearSVC) Classification Report:\\n\", class_report_svc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
